{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNXLuGz5nMRjKOma6utLGkr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"M0rrq3YccphK"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["### **Online Machine Learning: Key Facts**  \n","\n","#### **When to Use?**  \n","-**Real-time data** (e.g., stock prices, IoT sensors)  \n","-**Limited memory** (can’t store full dataset)  \n","-**Dynamic environments** (e.g., fraud detection, recommendations)  \n","-**Continuous model updates** needed  \n","\n","#### **How to Implement?**  \n","1. **Choose an online algorithm** (e.g., SGD, Online SVM, Bayesian updates).  \n","2. **Feed data sequentially** (one sample or mini-batch at a time).  \n","3. **Update model incrementally** (adjust weights per new data).  \n","4. **Monitor performance** (track drift/accuracy over time).  \n","\n","#### **Learning Rate**  \n","- **Critical for stability** – controls how much weights adjust per update.  \n","- **Too high** → overshooting/instability.  \n","- **Too low** → slow adaptation.  \n","- **Adaptive methods** (AdaGrad, Adam) auto-adjust rates.  \n","\n","#### **Out-of-Core Learning**  \n","- Handles **datasets too large for RAM** by streaming from disk.  \n","- Used in **big data** (e.g., TensorFlow’s `tf.data`, Vowpal Wabbit).  \n","\n","#### **Disadvantages**  \n"," **Noise sensitivity** – outliers can skew the model.  \n"," **Catastrophic forgetting** – may lose old patterns.  \n"," **Harder to debug** – no fixed train/test splits.  \n"," **Concept drift** – model must adapt to changing data.  \n","\n","---\n","\n","### **In Short**  \n","**Use when:** Real-time, low-memory, or dynamic data.  \n","**Implement via:** Incremental updates (SGD, Online SVM).  \n","**Tune learning rate** carefully (or use adaptive optimizers).  \n","**Out-of-core:** For huge datasets (stream from disk).  \n","**Watch out for:** Noise, forgetting, drift.  "],"metadata":{"id":"WL0qSJSYcvCt"}}]}